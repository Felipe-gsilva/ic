Similar ao processo de encontrar a linha de melhor ajuste na regressão linear, o objetivo do gradiente descendente é minimizar a função de custo ou o erro entre o y previsto e o y real. Para fazer isso, são necessários dois pontos de dados: uma direção e uma taxa de aprendizado. Esses fatores determinam os cálculos das derivadas parciais das iterações futuras, o que permite alcançar gradualmente o mínimo local ou global (ou seja, o ponto de convergência).

- A taxa de aprendizado é o tamanho das etapas necessárias para atingir o mínimo. Normalmente, esse é um valor pequeno e é avaliado e atualizado com base no comportamento da função de custo. Altas taxas de aprendizado resultam em etapas maiores, mas correm o risco de ultrapassar o mínimo. Por outro lado, uma taxa de aprendizado baixa tem tamanhos de etapas pequenos. Embora tenha a vantagem de maior precisão, o número de iterações compromete a eficiência geral, pois precisa de mais tempo e mais cálculos para atingir o mínimo.

- A função de custo (ou perda) mede a diferença, ou erro, entre o y real e o y previsto na sua posição atual. Isso melhora a eficácia do modelo de aprendizado de máquina, fornecendo feedback ao modelo para que ele possa ajustar os parâmetros para minimizar o erro e encontrar o mínimo local ou global. Ele itera continuamente, movendo-se ao longo da direção da descida mais íngreme (ou do gradiente negativo) até que a função de custo esteja próxima ou em zero. Neste ponto, o modelo parará de aprender. Além disso, embora os termos função de custo e função de perda sejam considerados sinônimos, há uma pequena diferença entre eles. Vale a pena observar que uma função de perda se refere ao erro de um exemplo de treinamento, enquanto uma função de custo calcula o erro médio em todo um conjunto de treinamento.